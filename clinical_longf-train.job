#!/bin/sh
#SBATCH --account=nlpgroup --partition=a100
#SBATCH --nodes=1 --ntasks=6
#SBATCH --gres=gpu:ampere:1
#SBATCH --job-name="clinical_bert-tune"
#SBATCH --mail-user=nrmyas001@cs.uct.ac.za
#SBATCH --mail-type=ALL
#SBATCH --time=00:10:00

module load software/TensorFlow-A100-GPU

export CUDA_VISIBLE_DEVICES=$(ncvd)
export TOKENIZERS_PARALLELISM=false
export SEQ_LEN=2048

python -m src.clinical_longformer.model.bert \
    /scrath/nrmyas001/datasets/discharge/$SEQ_LEN \
    --bert_pretrained_path=/scratch/nrmyas001/.data/pretraining_output/bert_uncased_L-12_H-768_A-12-$SEQ_LEN/$SEQ_LEN \
    --logdir=/mnt/lustre/users/ynurmahomed/lightning_logs \
    --batch_size=16 \
    --lr=5e-5 \
    --max_epochs=3 \
    --num_workers=6 \
    --gpus=1
